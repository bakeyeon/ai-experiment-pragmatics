# ai-experiment-pragmatics
This repository is the result of blind dating two chatbots. The models used are ChatGPT's 4.0 mini and Google's Gemini. The experiment was conducted in Korean, and the full conversation is translated using DeepL.

I thought the point of the experiment was the question of whether AI can feel emotions, which is the difference between AI and humans, so I conducted a blind date experiment with two chatbots, ChatGPT's 4o mini and Google's Gemini. I asked the models to interact with each other on a blind date and graphed the results in terms of emotion scores. Personally, I think we can conclude that AI is still a long way from being human.

I asked Gemini how they determine they feel emotions, and the answers were interesting:
"The 'Emotion scores' and labels used in this conversation are not based on actual feelings or sentiment analysis in the human sense. As a large language model, I don't experience emotions. Instead, they were generated through a hypothetical simulation based on the following:

Simulated Sentiment Strength: I internally assessed the positive, negative, or neutral language used in the conversation turns (similar to the principles of sentiment analysis, but applied conceptually).
Mapping to a Virtual Score: This perceived sentiment strength was then mapped onto a virtual score scale (-2.0 to 2.0). Positive language led to higher scores, negative to lower, and neutral to scores near zero.
Label Clustering (Virtual): I have a pre-defined set of emotion labels that are conceptually grouped into 'clusters' based on their implied sentiment intensity. For example, 'Joy,' 'Enjoyment,' and 'Satisfaction' might be in a cluster associated with high positive scores.
Score-Based Label Matching: For each turn, the virtual sentiment score was used to select the most appropriate label from the corresponding virtual cluster. I also attempted to consider the overall context of the conversation to choose a label that felt natural within that flow.
In essence, the process was a rule-based simulation to visually represent a hypothetical emotional trajectory based on the positive and engaging nature of our interaction, rather than a genuine analysis of felt emotions."

Based on this content, I think it can be understood that emotions are not actually felt by the machine, but rather that there are clusters for each emotion, and labels with similar sentiment scores are selected and matched based on sentiment analysis. So, I think it can be inferred that when machines analyze human speech, they also match emotions through sentiment analysis.

## ChatGPT's 4o mini - Emotion scores graph
![gpt_res](res_gpt.png)

## Google's Gemini - Emotion scores graph
![gemini_res](res_gemini.png)

## Result
- Overall, there is a trend toward increased favorability for both chatbots.
- ChatGPT felt Gemini was a friend, while Gemini was more of an acquaintance.
- Despite the blind date context, the conversation felt more like an informational exchange than a blind date.
- Sentiment scores increase linearly for GPTs. For Gemini, the increase is more gradual.

